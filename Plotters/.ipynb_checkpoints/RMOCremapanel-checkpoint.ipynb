{
 "metadata": {
  "name": "",
  "signature": "sha256:fe3f5cff9e6c997f8cf55287efb73ead163aabcd427d192bcba75bd8dcfbdad2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**PLOT a Pannel Plot of:**\n",
      "\n",
      "* **Psi** = remapped stream function:\n",
      "  $\\psi$(y,T(y,z)) put in terms of $\\psi(y,Z)$\n",
      "  This uses a linear interpolation to match grids and temperature bands\n",
      "  \n",
      "* **Psi Ed** = Eddy stream function\n",
      "  $\\psi_{eddy}=\\psi_{res}(y,Z)-\\overline{\\psi(y,Z)}$\n",
      "  \n",
      "* **K** = Eddy diffusivity\n",
      "  $K=-\\psi_{eddy}\\frac{\\overline{b_z}}{\\overline{b_y}}$\n",
      "  As from GM90 eddy parameterisation the eddy circulation can be thought of as this diffusivity multipied by isopycnal slope\n",
      "  \n",
      "Script overview:\n",
      "\n",
      "1. Chose one of the above pannels to plot\n",
      "\n",
      "2. Give it the file pattern (i.e. Where to search and what years do I want!). Do you want all runs possible? (pick Y or N)\n",
      "\n",
      "3. Load in modules\n",
      "\n",
      "4. I want to label my temperature contours nicely so i'm going to define a class to make the floats integers and write $^oC$ after it by adding in a custom format option.\n",
      "\n",
      "5. I need to define a function to return the nearest value in an array to the value given so I can remap the fields!\n",
      "\n",
      "6. Now I just have to check what runs I can find and generate a list of files I'm gonna look at.\n",
      "\n",
      "7. Now before starting best to load in constant Variables such as grid parameters and constants.\n",
      "\n",
      "8. Go into the main loop that's gonna read in the layers package data, calcuate the RMOC and then read in the temp field and find the depths of those temperatures and replot. Then calculate K and Eddy overturning. \n",
      "\n",
      "*I could really put steps 4,5,6 in to a file of common routines and import it in (For future runs)*\n",
      "\n",
      "*My regriding might need to be finner for that area of little stratification and it's putting everything in the lower bin!*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "VAR='Psi' #Pick what plot\n",
      "Full='N' # 9 Pannels isn't ideal for presentations N option give 4 plots"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Year='PSI.nc'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if Full=='N':\n",
      "   tau=['3','300','3000','Closed']\n",
      "   #tau=['NoQ'] \n",
      "else:\n",
      "    tau=['3','10','30','100','300','1000','3000','10000','Closed']\n",
      "x='/hpcdata/scratch/hb1g13/NchannelFlat'\n",
      "#x='/noc/msm/scratch/students/hb1g13/Mobilis'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.io import netcdf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import csv\n",
      "import sys\n",
      "import glob\n",
      "from scipy.interpolate import interp1d\n",
      "from scipy import interpolate\n",
      "from numba import autojit\n",
      "from pylab import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define a class that forces representation of float to look a certain way\n",
      "# This remove trailing zero so '1.0' becomes '1'\n",
      "class nf(float):\n",
      "     def __repr__(self):\n",
      "         str = '%.1f' % (self.__float__(),)\n",
      "         if str[-1]=='0':\n",
      "             return '%.0f' % self.__float__()\n",
      "         else:\n",
      "             return '%.1f' % self.__float__()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Label levels with specially formatted floats\n",
      "if plt.rcParams[\"text.usetex\"]:\n",
      "    fmt = r'%r $^oC$ %'\n",
      "else:\n",
      "    fmt = '%r $^oC$'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check=0\n",
      "runs=[]\n",
      "for i in range(len(tau)):\n",
      "    flist=x+'/'+str(tau[i])+'daynokpp/'+Year\n",
      "    if not os.path.exists(flist):\n",
      "       print 'WARNING: '+flist+' does not exist! (skipping this ta\\\n",
      "u...)'\n",
      "       check+=0\n",
      "    else:\n",
      "       check+=1\n",
      "       runs.append(i)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: /hpcdata/scratch/hb1g13/NchannelFlat/10000daynokpp/PSI.nc does not exist! (skipping this tau...)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_nearest(array,value):\n",
      "    idx = (np.abs(array-value)).argmin()\n",
      "    return array[idx]\n",
      "def regrid(Variable):\n",
      "    Vc=(Variable[:,0:-1]+Variable[:,1::])/2\n",
      "    return Vc\n",
      "numba_regrid = autojit()(regrid)\n",
      "numba_regrid.func_name = \"numba_regrid\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Runs=np.array(runs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha=2.000000E-04\n",
      "g=-9.81\n",
      "rho_0=1000\n",
      "C_p=3985"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gridfilepath=x+'/'+str(tau[0])+'daynokpp/'\n",
      "file2=netcdf.netcdf_file(gridfilepath+'grid.nc','r')\n",
      "Zp1=file2.variables['Zp1']\n",
      "Zp=Zp1[:]*1\n",
      "Z=file2.variables['Z']\n",
      "Z=Z[:]*1\n",
      "Y=file2.variables['Yp1']\n",
      "Y=Y[:]*1\n",
      "Yc=file2.variables['Y']\n",
      "Yc=Yc[:]*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig=plt.figure(figsize=(16.5,16.5))\n",
      "EDDY=[]\n",
      "MOC=[]\n",
      "for i in range(len(Runs)):\n",
      "    fname=x+'/'+str(tau[Runs[i]])+'daynokpp/'+Year\n",
      "    file2read = netcdf.NetCDFFile(fname,'r')\n",
      "    lvrho=file2read.variables[\"LaVH1TH\"]\n",
      "    lvrho=lvrho[:]\n",
      "    time=file2read.variables['T']\n",
      "    ti=time[:]\n",
      "    dx=Y[1]-Y[0] # Find Resolution\n",
      "    VT=np.sum(lvrho*dx,axis=3) #integrate Vdx along x\n",
      "    VTfdz=np.cumsum(VT[:,::-1,:],axis=1) #sum up the water column\n",
      "    psi=np.mean(VTfdz[:,::-1,:],axis=0)/10**6 #Time average and put into Sv and put back in right order\n",
      "    z=np.array(range(1,60))\n",
      "    Rho = np.genfromtxt(x+'/'+str(tau[Runs[i]])+'daynokpp/Temp', delimiter = ',')\n",
      "    nolayers=len(psi[:,1])\n",
      "    Rho=Rho[0:nolayers]#The layers package bins a layer so adjust \\\n",
      "    start=int(np.divide(ti[0],(86400*360)))#Find run start and sto\\\n",
      "    end=int(np.divide(ti[-1],(86400*360)))\n",
      "    a=list(fname)\n",
      "    a[-6]='a'\n",
      "    a[-5]='l'\n",
      "    a[-4]='l'\n",
      "    A=''.join(a)\n",
      "    if not os.path.isfile(A):\n",
      "       print \"Warning: file \"+A+\" not found, so i'll check for Tav file before skipping...\"\n",
      "       A=x+'/'+str(tau[Runs[i]])+'daynokpp/Tav.nc'\n",
      "       if not os.path.isfile(A):\n",
      "          continue\n",
      "    file2 = netcdf.NetCDFFile(A,'r')\n",
      "    Temp=file2.variables['THETA']\n",
      "    Temp=Temp[:]*1\n",
      "    Tav=np.mean(Temp,axis=0)\n",
      "    V=file2.variables['VVEL']\n",
      "    V=V[:]*1\n",
      "    Tavlat=np.mean(Tav,axis=2)\n",
      "    Vtave=np.mean(V,axis = 0)\n",
      "    Vtave[Vtave==0]=np.nan\n",
      "    Vzone=np.nansum(Vtave*dx,axis = 2)\n",
      "    dz=Zp[0:len(Zp)-1]-Zp[1:len(Zp)]\n",
      "    # No more super slow forloop!           \n",
      "    psi2=np.apply_along_axis(np.multiply,0,Vzone,dz)\n",
      "    psi3=np.cumsum(-psi2[::-1,:],axis=0)\n",
      "    npad = ((0,1), (0,0))\n",
      "    psi4 = np.pad(psi3, pad_width=npad, mode='constant', constant_values=0)\n",
      "    Psi=psi  #Convert to Sv\n",
      "    Psi2=psi4/10**6\n",
      "    MOC.append(np.nanmax(Psi2[3:-2,50:-50]))\n",
      "    Psi=numba_regrid(Psi)\n",
      "    Psi2=numba_regrid(Psi2)\n",
      "    #Remap Part                                                                                       \n",
      "    #Expand temperature co-ordinates (30 lvls to 168 lvls)                                            \n",
      "    Z2=interp1d(Z,Z,axis=0)\n",
      "    Znew=linspace(int(Z[0]),int(Z[-1]),168)\n",
      "    Zexp=Z2(Znew)\n",
      "    T2=interp1d(Z,Tavlat,axis=0)\n",
      "    Tnew=linspace(int(Z[0]),int(Z[-1]),168)\n",
      "    Texp=T2(Tnew)\n",
      "    R2=interp1d(Rho,Rho,axis=0)\n",
      "    Rnew=linspace(Rho[0],Rho[-1],168)\n",
      "    Rexp=R2(Rnew)\n",
      "    P2=interp1d(Rho,psi,axis=0)\n",
      "    Pnew=linspace(Rho[0],Rho[-1],168)\n",
      "    Pexp=P2(Pnew)\n",
      "    Psimap=np.zeros(shape(Texp))\n",
      "    for g in range(len(Yc)):\n",
      "        for k in range(len(Zexp)):\n",
      "            D=Texp[k,g]\n",
      "            if np.isnan(D):\n",
      "               Psimap[k,g]=np.nan\n",
      "            else:\n",
      "               P=Pexp[:,g]\n",
      "               I=find_nearest(Rexp, D)\n",
      "               b=nonzero(Rexp==I)[0][0]\n",
      "               Psimap[k,g]=P[b]\n",
      "    #Psimapped=np.multiply(Psimap,lmav) HFacS is req for topo runs                                    \n",
      "    #Psimap[Psimap==0]=np.nan NP can't do this!! 10000 yr has 0 residul\n",
      "    #Now put the MOC into 168 lvls to make the eddy plot     \n",
      "    P3=interp1d(Zp,Psi2,axis=0)\n",
      "    P3new=linspace(Z[0],Zp[-1],168)\n",
      "    P3exp=P3(P3new)\n",
      "    Psied=Psimap-P3exp\n",
      "    EDDY.append(np.nanmax(abs(Psied[7:-50,100:-100])))\n",
      "    Q_levs = np.arange(-20.5,20.5,1.5)\n",
      "    Psi_levs = Q_levs / 10\n",
      "    Ed_levs = np.arange(-3.5,3.5,.5)\n",
      "    Q_ticks = np.arange(-20.5,20.5,5.)\n",
      "    Psi_ticks = Q_ticks / 10\n",
      "    Eddy_ticks =  (np.arange(-25,25,.75))/10\n",
      "    E_levs = np.arange(-27.5,27.5,.75)\n",
      "    K_levs = (np.arange(-3000,6000,150))\n",
      "    K_ticks =(np.arange(-3000,6000,300))\n",
      "    # Lets Plot K\n",
      "    # K=-PsiEddy*dB_Z/dB_y\n",
      "    B=-g*alpha*Texp\n",
      "    By=np.apply_along_axis(np.multiply,0,np.ones(np.shape(Texp)),np.mean(B,axis=1))\n",
      "    Bz=np.apply_along_axis(np.multiply,1,np.ones(np.shape(Texp)),np.mean(B,axis=0))\n",
      "    #s=mean isopycnal slope!! mean by /mean bz!\n",
      "    K=-Psied*Bz/By*(10**6/5000)\n",
      "    if Full=='N':\n",
      "         ax = fig.add_subplot(2, 2, i+1)\n",
      "    else:\n",
      "         ax = fig.add_subplot(3, 3, i+1)\n",
      "    Psimap[Psimap>1.5]=1.5 #Force scale\n",
      "    Q2_levs = (np.arange(0,8,1))\n",
      "    if VAR=='K':\n",
      "        p=ax.contourf(Yc/1000,Zexp,K,K_levs,Psi_cmap=plt.cm.jet)\n",
      "    elif VAR=='PsiEd':\n",
      "        p=ax.contourf(Yc/1000,Zexp,Psied,Ed_levs,cmap=plt.cm.seismic) #Use b2r colourmap\n",
      "    else:\n",
      "        p=ax.contourf(Yc/1000,Zexp,Psimap,Psi_levs,cmap=plt.cm.seismic) #Use b2r colourmap\n",
      "    q=ax.contour(Yc/1000,Z,Tavlat,Q2_levs,colors='k',linewidths = 2)\n",
      "    q.levels = [nf(val) for val in q.levels ]\n",
      "    plt.clabel(q,q.levels[::2], inline=1,fmt=fmt, fontsize=10)\n",
      "    ax.set_title(str(tau[Runs[i]])+'day',fontsize=20)\n",
      "    if str(tau[Runs[i]])=='Closed':\n",
      "        ax.set_title(str(tau[Runs[i]]),fontsize=20)\n",
      "    ax.set_xlabel('Distance (km)',fontsize=20)\n",
      "    ax.set_ylabel('Depth (m)',fontsize=20)\n",
      "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
      "plt.tight_layout()\n",
      "q=( os.path.expanduser('~')+\"/Figures/Mobilis\")\n",
      "if not os.path.exists(q):\n",
      "       os.makedirs(q)\n",
      "cax = fig.add_axes([1, 0.1, 0.03, 0.8])\n",
      "if VAR=='K':\n",
      "    cbar=fig.colorbar(p, cax=cax, ticks=K_ticks) \n",
      "    cbar.ax.set_ylabel('$\\psi \\,\\, (sv)$',fontsize=20)\n",
      "    cbar.ax.tick_params(labelsize=30)\n",
      "    plt.savefig(q+\"/Kpanel\"+str(start)+\"-\"+str(end)+\".png\")\n",
      "elif VAR=='PsiEd':\n",
      "    cbar=fig.colorbar(p, cax=cax, ticks=Psi_ticks)\n",
      "    cbar.ax.set_ylabel('$\\psi \\,\\, (sv)$',fontsize=20)\n",
      "    cbar.ax.tick_params(labelsize=30)\n",
      "    plt.savefig(q+\"/EddyPsipanel\"+str(start)+\"-\"+str(end)+\".png\")\n",
      "else:\n",
      "    cbar=fig.colorbar(p, cax=cax,ticks=Psi_ticks)\n",
      "    cbar.ax.set_ylabel('$\\psi \\,\\, (sv)$',fontsize=20)\n",
      "    cbar.ax.tick_params(labelsize=30)\n",
      "    plt.savefig(q+\"/Remapanel\"+str(start)+\"-\"+str(end)+\".png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: file /hpcdata/scratch/hb1g13/NchannelFlat/3daynokpp/all.nc not found, so i'll check for Tav file before skipping...\n",
        "Warning: file /hpcdata/scratch/hb1g13/NchannelFlat/10daynokpp/all.nc not found, so i'll check for Tav file before skipping..."
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}